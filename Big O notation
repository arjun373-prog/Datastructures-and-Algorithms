Big O notation is special notation that tells you how fast an algorithm is. 
Who cares? Well, it turns out that you’ll use other people’s algorithms often—and when you do, it’s nice to understand how fast or slow they are.

For example, suppose you have a list of size n. Simple search needs to check each element, so it will take n operations. The run time in Big O notation is O(n).

note: Along with the worst-case run time, it’s also important to look at the average-case run time. 


Some common Big O run times : 
Here are five Big O run times that you’ll encounter a lot, sorted from fastest to slowest:
• O(log n), also known as log time. Example: Binary search.
• O(n), also known as linear time. Example: Simple search.
• O(n * log n). Example: A fast sorting algorithm, like quicksort 
• O(n2). Example: A slow sorting algorithm, like selection sort 
• O(n!). Example: A really slow algorithm, like the traveling salesperson 
There are other run times, too, but these are the five most common.

For now, the main takeaways are as follows:
• Algorithm speed isn’t measured in seconds, but in growth of the number of operations.
• Instead, we talk about how quickly the run time of an algorithm increases as the size of the input increases.
• Run time of algorithms is expressed in Big O notation.
• O(log n) is faster than O(n), but it gets a lot faster as the list of items you’re searching grows.

The traveling salesperson
